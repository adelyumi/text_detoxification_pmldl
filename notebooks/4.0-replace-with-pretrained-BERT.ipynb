{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de3c5db",
   "metadata": {},
   "source": [
    "# Replace toxic words with pretrained BERT model\n",
    "Here I will implement basic replace algorithm using pretrained BERT model. \n",
    "The main idea is to find \"toxic\" words in the text and replace them with the appropriate ones using pretrained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed8219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/external/en.txt') as file:\n",
    "    badwords = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd276a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2g1c',\n",
       " '2 girls 1 cup',\n",
       " 'acrotomophilia',\n",
       " 'alabama hot pocket',\n",
       " 'alaskan pipeline',\n",
       " 'anal',\n",
       " 'anilingus',\n",
       " 'anus',\n",
       " 'apeshit',\n",
       " 'arsehole']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badwords[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e164a9",
   "metadata": {},
   "source": [
    "Enhanced vocabulary is taken from https://github.com/Orthrus-Lexicon/Toxic/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614d5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/external/toxic_words.txt') as file:\n",
    "    toxic_words = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f30935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['***',\n",
       " '*itches',\n",
       " '4r5e',\n",
       " '5h1t',\n",
       " '5hit',\n",
       " 'God',\n",
       " 'God damn',\n",
       " 'Goddamn',\n",
       " 'a**',\n",
       " 'a*****es']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9dd6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fucking A your mom likes lan.</td>\n",
       "      <td>my mom loves you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We'll be fucking pariahs.</td>\n",
       "      <td>we're going to be completely unnerved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm done, Live Dead.</td>\n",
       "      <td>I'm through, Dead Meat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this place? A fucking vampire secret h...</td>\n",
       "      <td>that's a secret vampire headquarters.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just a silly dream and nothing more</td>\n",
       "      <td># Just a silky dream and nothing more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0                      Fucking A your mom likes lan.   \n",
       "1                          We'll be fucking pariahs.   \n",
       "2                               I'm done, Live Dead.   \n",
       "3  What is this place? A fucking vampire secret h...   \n",
       "4                Just a silly dream and nothing more   \n",
       "\n",
       "                              translation  \n",
       "0                       my mom loves you.  \n",
       "1  we're going to be completely unnerved.  \n",
       "2                 I'm through, Dead Meat.  \n",
       "3   that's a secret vampire headquarters.  \n",
       "4   # Just a silky dream and nothing more  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('../data/interim/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a50181",
   "metadata": {},
   "source": [
    "## Replacing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77827e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Load pretrained model\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56def971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_toxic_words(text, vocab):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    \n",
    "    toxic_word_indices = []\n",
    "    \n",
    "    masked_text = [token if token.lower() not in vocab else '[MASK]' for token in tokenized_text]\n",
    "    masked_text = \" \".join(masked_text)\n",
    "    \n",
    "    input_ids = tokenizer.encode(masked_text, add_special_tokens=True)\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_ids_tensor)[0]\n",
    "        predicted_tokens = []\n",
    "        \n",
    "        for i, token in enumerate(tokenized_text):\n",
    "            if token.lower() in vocab:\n",
    "                predicted_word = tokenizer.convert_ids_to_tokens(torch.argmax(predictions[0, i + 1]).item())\n",
    "                predicted_tokens.append(predicted_word)\n",
    "            else:\n",
    "                predicted_tokens.append(token)\n",
    "\n",
    "    replaced_text = tokenizer.convert_tokens_to_string(predicted_tokens)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b26e3",
   "metadata": {},
   "source": [
    "Let's see the performance of the algorithm on the first 2000 elements of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be51685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [09:18<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "size = 2000\n",
    "pred = []\n",
    "\n",
    "for i in tqdm(range(size)):\n",
    "    pred.append(replace_toxic_words(test_data.reference[i], badwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afebe7",
   "metadata": {},
   "source": [
    "New vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "944a7f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [09:00<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_new = []\n",
    "\n",
    "for i in tqdm(range(size)):\n",
    "    pred_new.append(replace_toxic_words(test_data.reference[i], toxic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e53c3",
   "metadata": {},
   "source": [
    "## Algorithm performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b4e9f",
   "metadata": {},
   "source": [
    "### Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed3d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0ee470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [06:29<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate toxicity of the algorithm: 0.5485283137535735\n"
     ]
    }
   ],
   "source": [
    "tox_values = []\n",
    "detox = Detoxify('unbiased')\n",
    "\n",
    "for i in tqdm(range(len(pred))):\n",
    "    tox_values.append(detox.predict(pred[i])['toxicity'])\n",
    "    \n",
    "print('Approximate toxicity of the algorithm:', sum(tox_values) / len(tox_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776d7d4",
   "metadata": {},
   "source": [
    "The toxicity reduced from 0.737 to 0.549. This metric could be improved with a larger list of toxic words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf171d5",
   "metadata": {},
   "source": [
    "New vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368bb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [06:40<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate toxicity of the algorithm: 0.31616000352780976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tox_values = []\n",
    "detox = Detoxify('unbiased')\n",
    "\n",
    "for i in tqdm(range(len(pred_new))):\n",
    "    tox_values.append(detox.predict(pred_new[i])['toxicity'])\n",
    "    \n",
    "print('Approximate toxicity of the algorithm:', sum(tox_values) / len(tox_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60563c",
   "metadata": {},
   "source": [
    "Wow, this is the improvement. Let's see other metrics and overall work of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63add38d",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc33c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9f1223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1010.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity: 0.9676834196750391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "cosine_sims = []\n",
    "\n",
    "for i in tqdm(range(len(pred))):\n",
    "    texts = [test_data.reference[i], pred[i]]\n",
    "    vector_matrix = count_vectorizer.fit_transform(texts)\n",
    "\n",
    "    cosine_sims.append(cosine_similarity(vector_matrix)[0][1])\n",
    "    \n",
    "print(\"Average similarity:\", sum(cosine_sims) / len(cosine_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8b52a",
   "metadata": {},
   "source": [
    "Similarity value is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7fbb9",
   "metadata": {},
   "source": [
    "New vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17952f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 951.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity: 0.9155217641994428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "cosine_sims = []\n",
    "\n",
    "for i in tqdm(range(len(pred_new))):\n",
    "    texts = [test_data.reference[i], pred_new[i]]\n",
    "    vector_matrix = count_vectorizer.fit_transform(texts)\n",
    "\n",
    "    cosine_sims.append(cosine_similarity(vector_matrix)[0][1])\n",
    "    \n",
    "print(\"Average similarity:\", sum(cosine_sims) / len(cosine_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86f1ad",
   "metadata": {},
   "source": [
    "The similarity reduced as expected, but still good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20ee72",
   "metadata": {},
   "source": [
    "## Examples of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef7fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Doesn't anybody in this town speak in complete fucking sentences anymore?\n",
      "Detoxifyed: Doesn't anybody in this town speak in complete coherent sentences anymore?\n",
      "\n",
      "Reference: you even tried to wipe your butt off.\n",
      "Detoxifyed: you even tried to wipe your face off.\n",
      "\n",
      "Reference: My eyes are fucked up.\n",
      "Detoxifyed: My eyes are fucked up.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [8, 58, 650]: \n",
    "    print(\"Reference:\", test_data.reference[i])\n",
    "    print(\"Detoxifyed:\", pred[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa780c",
   "metadata": {},
   "source": [
    "Comparing to the word removal, the semantic load of the sentence and grammatical logic are preserved. But (as seen in example 3) the algorithm depends on the bad words vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a4d4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Doesn't anybody in this town speak in complete fucking sentences anymore?\n",
      "Detoxifyed: Doesn't anybody in this town speak in complete coherent sentences anymore?\n",
      "\n",
      "Reference: you even tried to wipe your butt off.\n",
      "Detoxifyed: you even tried to wipe your face off.\n",
      "\n",
      "Reference: My eyes are fucked up.\n",
      "Detoxifyed: My eyes are tearing up.\n",
      "\n",
      "Reference: I told you bastards, don't waste ammunition!\n",
      "Detoxifyed: I told you before, don't waste ammunition!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [8, 58, 650, 46]: \n",
    "    print(\"Reference:\", test_data.reference[i])\n",
    "    print(\"Detoxifyed:\", pred_new[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c32ba",
   "metadata": {},
   "source": [
    "Fairly accurate work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79c6b8",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247a279",
   "metadata": {},
   "source": [
    "This is a simple method that does its job. However, it is unable to modify and recognize toxic constructs consisting of several words at once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
