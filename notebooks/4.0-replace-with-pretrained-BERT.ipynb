{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de3c5db",
   "metadata": {},
   "source": [
    "# Replace toxic words with pretrained BERT model\n",
    "Here I will implement basic replace algorithm using pretrained BERT model. \n",
    "The main idea is to find \"toxic\" words in the text and replace them with the appropriate ones using pretrained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed8219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/external/en.txt') as file:\n",
    "    badwords = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd276a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2g1c',\n",
       " '2 girls 1 cup',\n",
       " 'acrotomophilia',\n",
       " 'alabama hot pocket',\n",
       " 'alaskan pipeline',\n",
       " 'anal',\n",
       " 'anilingus',\n",
       " 'anus',\n",
       " 'apeshit',\n",
       " 'arsehole']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9dd6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fucking A your mom likes lan.</td>\n",
       "      <td>my mom loves you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We'll be fucking pariahs.</td>\n",
       "      <td>we're going to be completely unnerved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm done, Live Dead.</td>\n",
       "      <td>I'm through, Dead Meat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this place? A fucking vampire secret h...</td>\n",
       "      <td>that's a secret vampire headquarters.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just a silly dream and nothing more</td>\n",
       "      <td># Just a silky dream and nothing more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0                      Fucking A your mom likes lan.   \n",
       "1                          We'll be fucking pariahs.   \n",
       "2                               I'm done, Live Dead.   \n",
       "3  What is this place? A fucking vampire secret h...   \n",
       "4                Just a silly dream and nothing more   \n",
       "\n",
       "                              translation  \n",
       "0                       my mom loves you.  \n",
       "1  we're going to be completely unnerved.  \n",
       "2                 I'm through, Dead Meat.  \n",
       "3   that's a secret vampire headquarters.  \n",
       "4   # Just a silky dream and nothing more  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('../data/interim/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a50181",
   "metadata": {},
   "source": [
    "## Replacing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77827e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cbbec2fa3941c7aaab07bb25c6e36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)base-uncased/resolve/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe56f7ca9454fffb2c11814b32966cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Load pretrained model\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56def971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_toxic_words(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    \n",
    "    toxic_word_indices = []\n",
    "    \n",
    "    masked_text = [token if token.lower() not in badwords else '[MASK]' for token in tokenized_text]\n",
    "    masked_text = \" \".join(masked_text)\n",
    "    \n",
    "    input_ids = tokenizer.encode(masked_text, add_special_tokens=True)\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_ids_tensor)[0]\n",
    "        predicted_tokens = []\n",
    "        \n",
    "        for i, token in enumerate(tokenized_text):\n",
    "            if token.lower() in badwords:\n",
    "                predicted_word = tokenizer.convert_ids_to_tokens(torch.argmax(predictions[0, i + 1]).item())\n",
    "                predicted_tokens.append(predicted_word)\n",
    "            else:\n",
    "                predicted_tokens.append(token)\n",
    "\n",
    "    replaced_text = tokenizer.convert_tokens_to_string(predicted_tokens)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b26e3",
   "metadata": {},
   "source": [
    "Let's see the performance of the algorithm on the first 2000 elements of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5be51685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [08:17<00:00,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "size = 2000\n",
    "pred = []\n",
    "\n",
    "for i in tqdm(range(size)):\n",
    "    pred.append(replace_toxic_words(test_data.reference[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e53c3",
   "metadata": {},
   "source": [
    "## Algorithm performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b4e9f",
   "metadata": {},
   "source": [
    "### Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd0ee470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [04:16<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate toxicity of the algorithm: 0.5501514020925388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from detoxify import Detoxify\n",
    "\n",
    "tox_values = []\n",
    "detox = Detoxify('unbiased')\n",
    "\n",
    "for i in tqdm(range(len(pred))):\n",
    "    tox_values.append(detox.predict(pred[i])['toxicity'])\n",
    "    \n",
    "print('Approximate toxicity of the algorithm:', sum(tox_values) / len(tox_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776d7d4",
   "metadata": {},
   "source": [
    "The toxicity reduced from 0.737 to 0.55. This metric could be improved with a larger list of toxic words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63add38d",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9f1223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 925.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity: 0.965633296708456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "cosine_sims = []\n",
    "\n",
    "for i in tqdm(range(len(pred))):\n",
    "    texts = [test_data.reference[i], pred[i]]\n",
    "    vector_matrix = count_vectorizer.fit_transform(texts)\n",
    "\n",
    "    cosine_sims.append(cosine_similarity(vector_matrix)[0][1])\n",
    "    \n",
    "print(\"Average similarity:\", sum(cosine_sims) / len(cosine_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8b52a",
   "metadata": {},
   "source": [
    "Similarity value is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20ee72",
   "metadata": {},
   "source": [
    "## Examples of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ef7fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Doesn't anybody in this town speak in complete fucking sentences anymore?\n",
      "Detoxifyed: doesn't anybody in this town speak in complete english sentences anymore?\n",
      "\n",
      "Reference: you even tried to wipe your butt off.\n",
      "Detoxifyed: you even tried to wipe your hands off.\n",
      "\n",
      "Reference: My eyes are fucked up.\n",
      "Detoxifyed: my eyes are fucked up.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [8, 58, 650]: \n",
    "    print(\"Reference:\", test_data.reference[i])\n",
    "    print(\"Detoxifyed:\", pred[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa780c",
   "metadata": {},
   "source": [
    "Comparing to the word removal, the semantic load of the sentence and grammatical logic are preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79c6b8",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247a279",
   "metadata": {},
   "source": [
    "This is a simple method that does its job. However, it is very limited to a list of words (as seen in example three) and is unable to modify and recognize toxic constructs consisting of several words at once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
